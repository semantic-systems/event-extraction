name: "5 self attention layer"
seed: 42
model:
  from_pretrained: "language_models/CoyPu-CrisisLM-v1"
  layers:
    layer1:
      n_in: 768
      n_out: 20
  num_transformer_layers: 5
  freeze_transformer_layers: "none"
  learning_rate: 0.0001
  dropout_rate: 0.5
  epochs: 10
  output_path: "./outputs/"

data:
  name: "./event_extractor/custom_datasets/TRECIS_event_type.py"
  batch_size: 32
  label_column: "label"



