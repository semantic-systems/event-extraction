name: "emotion"
seed: 42
model:
  from_pretrained: "roberta-base"
  layers:
    layer1:
      n_in: 768
      n_out: 20
  num_transformer_layers: 2
  freeze_transformer_layers: "none"
  learning_rate: 0.0001
  dropout_rate: 0.5
  epochs: 5
  output_path: "./outputs/"
  L2_normalize_encoded_feature: False

data:
  name: "tweet_eval"
  config: "emotion"
  batch_size: 32
  label_column: "label"
  subset: 0.1




