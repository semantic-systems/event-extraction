augmenter:
  name: dropout
  num_samples: 2
data:
  batch_size: 32
  config: emotion
  include_oos: false
  label_column: label
  name: tweet_eval
  validation: true
early_stopping:
  delta: 0
  tolerance: 5
model:
<<<<<<< HEAD:event_extractor/configs/test/scl_second_training/mlp_dropout/05/emotion.yaml
  L2_normalize_encoded_feature: false
  L2_normalize_logits: false
  contrastive:
    base_temperature: 0.3
    contrast_mode: all
    contrastive_loss_ratio: 0
    temperature: 0.5
=======
  L2_normalize_encoded_feature: true
  L2_normalize_logits: false
>>>>>>> development:event_extractor/configs/tweeteval/sl/lm/roberta_base/emotion.yaml
  dropout_rate: 0.5
  epochs: 50
  freeze_transformer_layers: all
  from_pretrained: roberta-base
  layers:
    layer1:
      n_in: 768
      n_out: 20
  learning_rate: 1.0e-05
  load_ckpt: ./outputs/tweeteval/experiments/scl/mlp_dropout/05/emotion/seed_0/pretrained_models/emotion_best_model.pt
  num_transformer_layers: full
<<<<<<< HEAD:event_extractor/configs/test/scl_second_training/mlp_dropout/05/emotion.yaml
  output_path: ./outputs/tweeteval/experiments/scl_second_training/mlp_dropout/05/
=======
  output_path: ./outputs/tweeteval/experiments/sl/lm/roberta_base/
>>>>>>> development:event_extractor/configs/tweeteval/sl/lm/roberta_base/emotion.yaml
name: emotion
seed:
- 0
visualizer:
- tsne
